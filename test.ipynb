{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7b19a757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "90d8fd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(id):\n",
    "\n",
    "    transform = transforms.Compose([transforms.Grayscale(), \n",
    "                                transforms.Resize((64, 64)), \n",
    "                                transforms.ToTensor()])\n",
    "    \n",
    "    if(id == 1):\n",
    "        dataset = torchvision.datasets.ImageFolder(root='./client1', transform=transform)\n",
    "    elif(id == 2):\n",
    "        dataset = torchvision.datasets.ImageFolder(root='./client2', transform=transform)\n",
    "    elif(id == 3):\n",
    "        dataset = torchvision.datasets.ImageFolder(root='./client3', transform=transform)\n",
    "    elif(id == 4):\n",
    "        dataset = torchvision.datasets.ImageFolder(root='./client4', transform=transform)\n",
    "    elif(id == 5):\n",
    "        dataset = torchvision.datasets.ImageFolder(root='./client5', transform=transform)\n",
    "    elif(id == 6):\n",
    "        dataset = torchvision.datasets.ImageFolder(root='./client6', transform=transform)\n",
    "    elif(id == 7):\n",
    "        dataset = torchvision.datasets.ImageFolder(root='./client7', transform=transform)\n",
    "    elif(id == 8):\n",
    "        dataset = torchvision.datasets.ImageFolder(root='./client8', transform=transform)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid client ID.\")\n",
    "\n",
    "    train_ratio = 0.8\n",
    "    size = len(dataset)\n",
    "    train_size = int(train_ratio * size)\n",
    "    test_size = size - train_size\n",
    "\n",
    "    generator = torch.Generator().manual_seed(42)\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size], generator=generator)\n",
    "\n",
    "    train_dataset, test_dataset = mappingLable(id, train_dataset, test_dataset)\n",
    "\n",
    "    batch_size = 32\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "class MappedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, subset, label_map):\n",
    "        self.subset = subset\n",
    "        self.label_map = label_map\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.subset[idx]\n",
    "        # Nếu nhãn có trong map thì đổi, ngược lại giữ nguyên\n",
    "        y = self.label_map.get(y, y)\n",
    "        return x, y\n",
    "\n",
    "def mappingLable(id, train, test):\n",
    "    #Mapped Lables\n",
    "    lable_map1 = {0: 0, 1: 1, 2: 2}\n",
    "    lable_map2 = {0: 3, 1: 4, 2: 5}\n",
    "    lable_map3 = {0: 6, 1: 7, 2: 8}\n",
    "    lable_map4 = {0: 9, 1: 10, 2: 11}\n",
    "    lable_map5 = {0: 12, 1: 13, 2: 14}\n",
    "    lable_map6 = {0: 15, 1: 16, 2: 17}\n",
    "    lable_map7 = {0: 18, 1: 19, 2: 20}\n",
    "    lable_map8 = {0: 21, 1: 22, 2: 23, 3: 24}\n",
    "\n",
    "    if id == 1:\n",
    "        trainset = MappedDataset(train, label_map=lable_map1)\n",
    "        testset = MappedDataset(test, label_map=lable_map1)\n",
    "    elif id == 2:\n",
    "        trainset = MappedDataset(train, label_map=lable_map2)\n",
    "        testset = MappedDataset(test, label_map=lable_map2)\n",
    "    elif id == 3:\n",
    "        trainset = MappedDataset(train, label_map=lable_map3)\n",
    "        testset = MappedDataset(test, label_map=lable_map3)\n",
    "    elif id == 4:\n",
    "        trainset = MappedDataset(train, label_map=lable_map4)\n",
    "        testset = MappedDataset(test, label_map=lable_map4)\n",
    "    elif id == 5:\n",
    "        trainset = MappedDataset(train, label_map=lable_map5)\n",
    "        testset = MappedDataset(test, label_map=lable_map5)\n",
    "    elif id == 6:\n",
    "        trainset = MappedDataset(train, label_map=lable_map6)\n",
    "        testset = MappedDataset(test, label_map=lable_map6)\n",
    "    elif id == 7:\n",
    "        trainset = MappedDataset(train, label_map=lable_map7)\n",
    "        testset = MappedDataset(test, label_map=lable_map7)\n",
    "    elif id == 8:\n",
    "        trainset = MappedDataset(train, label_map=lable_map8)\n",
    "        testset = MappedDataset(test, label_map=lable_map8)\n",
    "\n",
    "    return trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "be36a029",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader1, testloader1 = load_data(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8ba6d7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x0000020CD0737090>\n"
     ]
    }
   ],
   "source": [
    "print(testloader1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e3b85fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 64, 64]) tensor([22, 22, 22, 24, 23, 24, 24, 22, 21, 22, 24, 24, 24, 24, 23, 23, 24, 24,\n",
      "        24, 23, 22, 22, 24, 22, 24, 21, 21, 22, 21, 24, 24, 24])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in testloader1:\n",
    "    print(images.shape, labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c810a33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=25, num_filters_conv1=32, num_filters_conv2=64, fc1_neurons=128, image_size=64):\n",
    "        super().__init__()\n",
    "        self.conv_layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, num_filters_conv1, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        image_size = image_size // 2\n",
    "        self.conv_layer2 = nn.Sequential(\n",
    "            nn.Conv2d(num_filters_conv1, num_filters_conv2, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        image_size = image_size // 2\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(image_size * image_size * num_filters_conv2, fc1_neurons),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(fc1_neurons, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer1(x)\n",
    "        x = self.conv_layer2(x)\n",
    "        x = x.view(x.size(0), -1) # Flatten the output for the linear layers\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "170289be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "907b0a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (conv_layer1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv_layer2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_layers): Sequential(\n",
       "    (0): Linear(in_features=16384, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=25, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))\n",
    "lossFn = torch.nn.CrossEntropyLoss().to(torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "819b6469",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = None\n",
    "\n",
    "for images, labels in testloader1:\n",
    "    image = images\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a0b916d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d4c918c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image.to(torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "657b3d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ec35cd49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 25])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218ca00b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5d508a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv311 (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
